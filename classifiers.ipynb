{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d890edb8",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33deac54",
   "metadata": {},
   "source": [
    "**有监督学习**\n",
    "|       | probabilistic     | non-probabilistic  |\n",
    "| -------- | -------- | -------- |\n",
    "| classification | Discriminative \\\\ Generative | SVM、perceptron、NN不用softmax  |\n",
    "| regression | - | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499cf7b0",
   "metadata": {},
   "source": [
    "<font color=blue>分类问题如果线性可分，用perceptron model。但实践中基本都是线性不可分问题，此时就要用MLP(multi-layer perceptron)来求解。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93497ad",
   "metadata": {},
   "source": [
    "## I. 分类问题的求解框架\n",
    "$$\n",
    "input \\rightarrow  feature\\ extraction(representation) \\rightarrow classifier \\underset{optimization}{\\rightarrow}  cost function\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af38a0e",
   "metadata": {},
   "source": [
    "## II. 解概率分类问题的最优分类器：Bayes classifer\n",
    "bayes classifier不涉及$P(y|x)$的具体形式，所以对discriminative和generative classifier都适用。\n",
    "### 2.1 贝叶斯分类器的定义\n",
    "1. 设定：\\\n",
    "(1)分类问题：$x\\in R^d,y\\in \\{1, ..., K\\}$,classifier c(x)为映射：$R^d\\rightarrow\\{1, ..., K\\}$ \\\n",
    "(2)概率分布：似然$P(x|y=k)$,先验$P(y=k)=\\phi_k, {\\textstyle \\sum_{k=1}^{K}}\\phi_k=1$ \\\n",
    "(3)定义classifier c在已知x取值条件下的错误率为：$R(c_x)=R(c(x))=P(C(x)\\ne y)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d697e4da",
   "metadata": {},
   "source": [
    "2. 定义Bayes Classifier：$c_B(x)=\\underset{k\\in \\{1, ..., K\\}}{argmax} P(y=k|x)$ \\\n",
    "<font color=red>**含义：给定x，bayes classifier是使后验概率$P(y=k|x)$最大的分类器。**</font> \\\n",
    "以二分类问题为例，取$y\\in \\{0, 1\\}$,则\n",
    "$$c_B(x)= \\left\\{\\begin{matrix}\n",
    "1  &if,p(y=1|x)\\ge p(y=0|x)  \\\\\n",
    "0  &if,p(y=1|x)<  p(y=0|x) \n",
    "\\end{matrix}\\right.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de42970",
   "metadata": {},
   "source": [
    "### 2.2 性质：如果知道feature的概率分布，那么贝叶斯分类器能最小化misclassification的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ee34cd",
   "metadata": {},
   "source": [
    "<font color=green>**以二分类问题为例的证明：$c_B$的error rate$R(c_B)$是所有分类器中最小的**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952fb330",
   "metadata": {},
   "source": [
    "取$\\eta(x)=P(y=1|x)$,则$$\n",
    "\\begin{align}\n",
    " R(c_x)&=P(C(x)\\ne y)\\\\\n",
    "&= \\left\\{\\begin{matrix}\n",
    "P(y=0|x)  & if, c(x)=1 \\\\\n",
    "P(y=1|x)  & if, c(x)=0 \n",
    "\\end{matrix}\\right.\\\\\n",
    "&=\\left\\{\\begin{matrix}\n",
    "1-\\eta(x)  &if,c(x) & = 1 \\\\\n",
    "\\eta(x)  &if,c(x) & = 0\n",
    "\\end{matrix}\\right.  \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca1066",
   "metadata": {},
   "source": [
    "尽管$\\eta(x)$未知，但是它是由分布给定的，所以$R(c_x)$有下界：\n",
    "$$\n",
    "minR(c_x)=min((1-\\eta(x)), \\eta(x))\n",
    "$$\n",
    "<img src=\"./pics/bayes_classifier_pic1.jpg\" style=\"zoom:40%\">\n",
    "因此，只要分类器能处处取到$minR(c_x)$，该分类器就是最优分类器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8169b732",
   "metadata": {},
   "source": [
    "根据$c_B$的定义:$$\n",
    "\\begin{align}\n",
    "c_B(x)\n",
    "&= \\left\\{\\begin{matrix}\n",
    "1  &if,p(y=1|x)\\ge p(y=0|x)  \\\\\n",
    "0  &if,p(y=1|x)<  p(y=0|x) \n",
    "\\end{matrix}\\right.\\\\\n",
    "&= \\left\\{\\begin{matrix}\n",
    "1  &if,\\eta(x)\\ge 1-\\eta(x)  \\\\\n",
    "0  &if,\\eta(x)< 1-\\eta(x)\n",
    "\\end{matrix}\\right.  \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ce0ea",
   "metadata": {},
   "source": [
    "此时有：$$\n",
    "\\begin{align}\n",
    "R(c_B)\n",
    "&= \\left\\{\\begin{matrix}\n",
    "p(y=0|x)  &if,p(y=1|x)\\ge p(y=0|x)  \\\\\n",
    "p(y=1|x)  &if,p(y=1|x)<  p(y=0|x) \n",
    "\\end{matrix}\\right.\\\\\n",
    "&= \\left\\{\\begin{matrix}\n",
    "1-\\eta(x)  &if,1-\\eta(x)\\le \\eta(x) \\\\\n",
    "\\eta(x)  &if,1-\\eta(x)> \\eta(x)\n",
    "\\end{matrix}\\right.  \\\\\n",
    "&=minR(c_x)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3974c4e8",
   "metadata": {},
   "source": [
    "### 2.3 实现方式\n",
    "1. <font color=red>**bayes classifier为分类问题的处理提供了基本原则。但一般问题中，$p(y|x)$是未知的，所以无法直接使用该classifier。**</font>\n",
    "2. <font color=blue>**有两类确定$p(y|x)$的方法：Discriminative和Generative model。**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219347fe",
   "metadata": {},
   "source": [
    "## III. Generative model和Discriminative model\n",
    "<font color=green>**关键区别：**两种model在处理分类问题时的核心差异在于寻找$p(y|x)$时使用的方法不同。</font>\n",
    "1. Generative model假设x和y都是随机变量，有联合分布$p(x,y)$。利用关系$p(y|x)=\\frac{p(x,y)}{p(x)}=\\frac{p(x|y;\\theta)p(y;\\varphi )}{p(x)}$对先验和似然建模求参数\n",
    "2. Discriminative model假设x是固定的，只有y是随机变量，直接对$p(y|x;\\theta)$的分布建模求参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6542997f",
   "metadata": {},
   "source": [
    "### 3.1 **<font color=orange>Generative model</font>**\n",
    "#### 3.1.1 模型的基本框架\n",
    "1. 模型训练时：用贝叶斯分析方式对$𝑃(𝑦|𝑋)$做分解，转化为对先验分布$P(y_i;φ)$和似然$P(X|y_i;θ)$建模，用MLE或者CE做目标函数，求解参数θ和$\\varphi$。\\\n",
    "贝叶斯分析：\\\n",
    "$P(y_i|X) = \\frac{P(X|y_i)*P(y_i)}{P(X)} = \\frac{P(X|y_i)*P(y_i)}{Σ_{y_j\\in{Y}} P(X|y_j)*P(y_j)}$ \\\n",
    "求解MLE：\\\n",
    "$\\hat{θ}=\\underset{θ,φ}{argmax}\\ L(θ,φ) = \\underset{θ,φ}{argmax}\\ \\frac{P(X|y_i;θ)*P(y_i;φ)}{Σ_{y_j\\in{Y}} P(X|y_j;θ)*P(y_j;φ)}$\n",
    "2. 模型推理时：同样利用贝叶斯关系对目标函数做分析，求解优化函数。 \\\n",
    "利用贝叶斯分析： \\\n",
    "$\\hat{y}=\\underset{y}{argmax}P(y|X) = \\underset{y}{argmax}\\frac{P(X|y)*P(y)}{P(X)}$ \\\n",
    "<font color=red>由于y的取值与P(X)无关</font>，因此有：\\\n",
    "$\\hat{y}=\\underset{y}{argmax}\\ P(X|y;\\hat{θ})*P(y;\\hat{φ})=\\underset{y}{argmax}\\ P(X,y;\\hat{θ},\\hat{φ})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21eb6c7",
   "metadata": {},
   "source": [
    "#### 3.1.2 例1：GDA——从Generative model的视角理解logistic regression\n",
    "1. <font color=blue>**本质：似然是Gaussion的2分类问题用Generative model得到的后验分布正好是Logistic**</font>\n",
    "2. 设定：\n",
    "3. 分析过程：详见cs229笔记page13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515b1199",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3eb5ad65",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79a4dd99",
   "metadata": {},
   "source": [
    "### 3.2 **<font color=orange>Discriminative model</font>**\n",
    "#### 3.2.1 模型的基本框架\n",
    "1. 模型训练时：直接对$P(y|X)$的参数建模，用MLE或者CE做目标函数，求解参数θ:\n",
    "$\\hat{θ}=\\underset{θ}{argmax}\\ L(θ) = \\underset{θ}{argmax}\\ \\underset{i}{Σ}logP(y_{i}|X_{i};θ)$\n",
    "2. 模型推理时：直接用估计的条件概率分布求概率最大的类型： \\\n",
    "$\\hat{y}=\\underset{y}{argmax}P(y|X;\\hat{θ})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b8047b",
   "metadata": {},
   "source": [
    "#### 3.2.2 例1：LR——从Discriminative model的视角理解logistic regression\n",
    "直接以logistc函数的形态作为$p(y|x)$的近似。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cbf84c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d79ec19",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34ef2ec7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c2e468b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c08923f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1738070",
   "metadata": {},
   "source": [
    "<font color=green>**以二分类问题为例的证明：取$\\bar R(c)$为正确率的期望，即$\\bar R(c)= 1-R(c)$，则$\\bar R(c_B)=max\\bar R(c)$**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c04f0bd",
   "metadata": {},
   "source": [
    "1. 补充定义classifer c的错误率：$R(c)=E_{(x,y)}1\\{c(x)\\ne y\\}$，即，用$R(c_x)$的期望值来衡量分类器的错误率。\n",
    "如果用错误率的期望来衡量分类器的整体错误率，则：$$\n",
    "\\begin{align*}\n",
    "R(c)\n",
    "&=E_{(x,y)}1\\{c(x)\\ne y\\} \\\\\n",
    "&=E_xE_{y|x}1\\{c(x)\\ne y\\}\\\\\n",
    "&=E_x[ {\\textstyle \\sum_{y|x}}P(y|x)*1\\{c(x)\\ne y\\} ]\\\\\n",
    "&=E_x[ P(y=0|x)*1\\{c(x)=1\\} + P(y=1|x)*1\\{c(x)=0\\}]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b351f8",
   "metadata": {},
   "source": [
    "取$\\eta(x)=P(y=1|x)$,则：\n",
    "$$\n",
    "\\begin{align*}\n",
    "E[R(c)] \n",
    "&=E_x[ (1-\\eta(x))*1\\{c(x)=1\\} + \\eta(x)*1\\{c(x)=0\\}]\\\\\n",
    "&=E_{x:c(x)=1}[1-\\eta(x)]+E_{x:c(x)=0}[\\eta(x)]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa54be8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "040efd3c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
